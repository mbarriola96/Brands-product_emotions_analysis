{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_product(tweet_text):\n",
    "    \"\"\"\n",
    "    Identify if the tweet is about a Google or Apple product, and replace any product-related keywords\n",
    "    with 'tecproduct'.\n",
    "    \n",
    "    Parameters:\n",
    "    tweet_text (str): The text of the tweet.\n",
    "    \n",
    "    Returns:\n",
    "    str: 'Google' if the tweet mentions a Google product, 'Apple' if the tweet mentions an Apple product,\n",
    "         'Both' if the tweet mentions both, 'Unknown' if it mentions neither.\n",
    "    \"\"\"\n",
    "    google_keywords = ['google', 'pixel', 'pixels', 'nexus', 'nexuses', 'android', 'androids', \n",
    "                       'chromebook', 'chromebooks', 'nest', 'nests', 'stadia', 'stadias']\n",
    "    apple_keywords = ['apple', 'apples', 'iphone', 'iphones', 'ipad', 'ipads', 'macbook', \n",
    "                      'macbooks', 'imac', 'imacs', 'watch', 'watches', 'airpods', \n",
    "                      'appstore', 'ios', 'itunes']\n",
    "    \n",
    "    # Ensure tweet_text is a string\n",
    "    if not isinstance(tweet_text, str):\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Replace \"app store\" with \"appstore\" before tokenization\n",
    "    tweet_text = tweet_text.replace(\"app store\", \"appstore\")\n",
    "    \n",
    "    # Replace any occurrences of google_keywords and apple_keywords with 'tecproduct'\n",
    "    for keyword in google_keywords + apple_keywords:\n",
    "        tweet_text = re.sub(rf'\\b{keyword}\\b', 'tecproduct', tweet_text, flags=re.IGNORECASE)\n",
    "    \n",
    "    return tweet_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to clean and preprocess tweets\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove strange characters and punctuation\n",
    "    strange_chars = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~“!#Ûª'\n",
    "    text = text.translate(str.maketrans(strange_chars, ' ' * len(strange_chars)))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_product_mention(df):\n",
    "    df['product_mention'] = df['product_mention'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Import the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_type</th>\n",
       "      <th>product_mention</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple</td>\n",
       "      <td>.@wesley83 I have a 3G tecproduct. After 3 hrs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome tecpro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "      <td>@swonderlin Can not wait for #tecproduct 2 als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple</td>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Google</td>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7928</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "      <td>tecproduct everywhere. #SXSW {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Google</td>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7930</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Google</td>\n",
       "      <td>tecproduct's Zeiger, a physician never reporte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Some Verizon tecproduct customers complained t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Google</td>\n",
       "      <td>Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7933 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text      emotion_type  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...  Negative emotion   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...  Positive emotion   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...  Positive emotion   \n",
       "3     @sxsw I hope this year's festival isn't as cra...  Negative emotion   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...  Positive emotion   \n",
       "...                                                 ...               ...   \n",
       "7928                      Ipad everywhere. #SXSW {link}  Positive emotion   \n",
       "7929  Wave, buzz... RT @mention We interrupt your re...           unknown   \n",
       "7930  Google's Zeiger, a physician never reported po...           unknown   \n",
       "7931  Some Verizon iPhone customers complained their...           unknown   \n",
       "7932  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...           unknown   \n",
       "\n",
       "     product_mention                                       cleaned_text  \n",
       "0              Apple  .@wesley83 I have a 3G tecproduct. After 3 hrs...  \n",
       "1              Apple  @jessedee Know about @fludapp ? Awesome tecpro...  \n",
       "2              Apple  @swonderlin Can not wait for #tecproduct 2 als...  \n",
       "3              Apple  @sxsw I hope this year's festival isn't as cra...  \n",
       "4             Google  @sxtxstate great stuff on Fri #SXSW: Marissa M...  \n",
       "...              ...                                                ...  \n",
       "7928           Apple                tecproduct everywhere. #SXSW {link}  \n",
       "7929          Google  Wave, buzz... RT @mention We interrupt your re...  \n",
       "7930          Google  tecproduct's Zeiger, a physician never reporte...  \n",
       "7931           Apple  Some Verizon tecproduct customers complained t...  \n",
       "7932          Google  Ï¡Ïàü_ÊÎÒ£Áââ_£â_ÛâRT @...  \n",
       "\n",
       "[7933 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv('df.csv')\n",
    "df['cleaned_text'] = df['tweet_text'].apply(identify_product)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "df['cleaned_text'] = df['tweet_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Negative emotion       0.68      0.22      0.33        95\n",
      "Positive emotion       0.69      0.45      0.55       609\n",
      "         unknown       0.66      0.86      0.75       883\n",
      "\n",
      "        accuracy                           0.67      1587\n",
      "       macro avg       0.67      0.51      0.54      1587\n",
      "    weighted avg       0.67      0.67      0.65      1587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Preparar características y etiquetas\n",
    "texts = df['cleaned_text']\n",
    "product_mentions = df['product_mention']\n",
    "labels = df['emotion_type']\n",
    "\n",
    "# Crear un DataFrame para las características\n",
    "X = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'product': product_mentions\n",
    "})\n",
    "\n",
    "# Separar los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocesar el texto (limitando a las 2000 palabras más importantes)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000)\n",
    "X_train_text = tfidf_vectorizer.fit_transform(X_train['text'])\n",
    "X_test_text = tfidf_vectorizer.transform(X_test['text'])\n",
    "\n",
    "# Preprocesar la columna categórica\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X_train_product = onehot_encoder.fit_transform(X_train[['product']])\n",
    "X_test_product = onehot_encoder.transform(X_test[['product']])\n",
    "\n",
    "# Concatenar las características procesadas\n",
    "X_train_processed = np.hstack([X_train_text.toarray()])\n",
    "X_test_processed = np.hstack([X_test_text.toarray()])\n",
    "\n",
    "# Crear y ajustar el modelo\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda en malla con validación cruzada\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_processed, y_train)\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "y_pred = grid_search.predict(X_test_processed)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Feature  Importance\n",
      "1006     link    0.016384\n",
      "909      ipad    0.015454\n",
      "757     great    0.013219\n",
      "747    google    0.010689\n",
      "120   awesome    0.010104\n",
      "1460       rt    0.010039\n",
      "74        app    0.009676\n",
      "77      apple    0.009364\n",
      "371      cool    0.008620\n",
      "1662    store    0.008262\n",
      "1166      new    0.006650\n",
      "911    iphone    0.006466\n",
      "744      good    0.006370\n",
      "1173     nice    0.005981\n",
      "55        amp    0.005945\n",
      "1037     love    0.005859\n",
      "109    austin    0.005383\n",
      "1384     quot    0.005120\n",
      "1703     sxsw    0.004664\n",
      "1310      pop    0.004662\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Obtener las importancias de las características\n",
    "feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Obtener los nombres de las características\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "all_feature_names = np.concatenate([tfidf_feature_names])\n",
    "\n",
    "# Crear un DataFrame con las importancias de las características\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': all_feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Ordenar las características por importancia\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Mostrar las características más importantes\n",
    "print(importance_df.head(20))\n",
    "\n",
    "# Graficar las importancias de las características\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['Feature'][:20], importance_df['Importance'][:20])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 20 Features by Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 características más importantes para la clase 'Negative emotion':\n",
      "link: 0.0164\n",
      "ipad: 0.0154\n",
      "great: 0.0132\n",
      "google: 0.0107\n",
      "awesome: 0.0101\n",
      "rt: 0.0100\n",
      "app: 0.0097\n",
      "apple: 0.0094\n",
      "cool: 0.0086\n",
      "store: 0.0082\n",
      "\n",
      "Top 10 características más importantes para la clase 'Positive emotion':\n",
      "link: 0.0164\n",
      "ipad: 0.0155\n",
      "great: 0.0132\n",
      "google: 0.0107\n",
      "awesome: 0.0101\n",
      "rt: 0.0100\n",
      "app: 0.0097\n",
      "apple: 0.0094\n",
      "cool: 0.0086\n",
      "store: 0.0083\n",
      "\n",
      "Top 10 características más importantes para la clase 'unknown':\n",
      "link: 0.0164\n",
      "ipad: 0.0155\n",
      "great: 0.0132\n",
      "google: 0.0107\n",
      "awesome: 0.0101\n",
      "rt: 0.0100\n",
      "app: 0.0097\n",
      "apple: 0.0094\n",
      "cool: 0.0086\n",
      "store: 0.0083\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Ajustar el modelo con los mejores parámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Obtener la importancia de características global\n",
    "global_feature_importances = best_model.feature_importances_\n",
    "\n",
    "# Inicializar una lista para almacenar la importancia por clasez\n",
    "class_feature_importances = []\n",
    "\n",
    "# Obtener la importancia de características por clase\n",
    "for class_index in range(len(best_model.classes_)):\n",
    "    class_importance = np.zeros_like(global_feature_importances)\n",
    "    \n",
    "    for tree in best_model.estimators_:\n",
    "        # Obtener la probabilidad predicha por este árbol para la clase actual\n",
    "        tree_class_prob = tree.predict_proba(X_train_processed)[:, class_index]\n",
    "        \n",
    "        # Multiplicar la importancia de características por la probabilidad de clase\n",
    "        class_importance += tree.feature_importances_ * tree_class_prob.sum()\n",
    "\n",
    "    # Normalizar la importancia para la clase\n",
    "    class_importance /= class_importance.sum()\n",
    "    class_feature_importances.append(class_importance)\n",
    "\n",
    "# Mostrar las 10 características más importantes para cada clase\n",
    "for class_index, class_name in enumerate(best_model.classes_):\n",
    "    print(f\"\\nTop 10 características más importantes para la clase '{class_name}':\")\n",
    "    sorted_indices = np.argsort(class_feature_importances[class_index])[::-1]\n",
    "    for i in sorted_indices[:10]:\n",
    "        print(f\"{feature_names[i]}: {class_feature_importances[class_index][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "df['cleaned_text'] = df['tweet_text'].apply(clean_text)\n",
    "\n",
    "# Prepare features and labels\n",
    "texts = df['cleaned_text']\n",
    "product_mentions = df['product_mention']\n",
    "labels = df['emotion_type']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Define preprocessing for text and product mention\n",
    "text_preprocessor = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, max_df=0.7, min_df=5))\n",
    "])\n",
    "\n",
    "product_mention_preprocessor = Pipeline([\n",
    "    ('preprocessor', FunctionTransformer(preprocess_product_mention, validate=False)),\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create Column Transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cleaned_text', text_preprocessor, 'cleaned_text'),\n",
    "        ('product_mention', product_mention_preprocessor, 'product_mention')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define models\n",
    "def build_lstm_model(epochs=10):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_bidirectional_lstm_model(epochs=10):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn_lstm_model(epochs=10):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_deep_nn_model(epochs=10):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# XGBoost model\n",
    "def build_xgboost_model():\n",
    "    return XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# Create a pipeline with preprocessing and model\n",
    "def create_pipeline(model_func, **kwargs):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model_func(**kwargs))\n",
    "    ])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['cleaned_text', 'product_mention']], labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grids for tuning\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.1, 1, 10]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [10, 20]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    'LSTM': {'classifier__epochs': [5, 10, 15]},\n",
    "    'Bidirectional LSTM': {'classifier__epochs': [5, 10, 15]},\n",
    "    'CNN + LSTM': {'classifier__epochs': [5, 10, 15]},\n",
    "    'Deep NN': {'classifier__epochs': [5, 10, 15]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning model: Logistic Regression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 9 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2895, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 98, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index_class_helper.pxi\", line 93, in pandas._libs.index.Int64Engine._check_type\nKeyError: 'product_mention'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 754, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 681, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n    return super().__call__(iterable_with_config)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 240, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 312, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"<ipython-input-3-be33faf0ed4d>\", line 2, in preprocess_product_mention\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\", line 882, in __getitem__\n    return self._get_value(key)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\", line 989, in _get_value\n    loc = self.index.get_loc(label)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2897, in get_loc\n    raise KeyError(key) from err\nKeyError: 'product_mention'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2690d14011dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    896\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1421\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1422\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    873\u001b[0m                     )\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m                 \u001b[1;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             )\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 9 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2895, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 98, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index_class_helper.pxi\", line 93, in pandas._libs.index.Int64Engine._check_type\nKeyError: 'product_mention'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 754, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 681, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n    return super().__call__(iterable_with_config)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 240, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 312, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"<ipython-input-3-be33faf0ed4d>\", line 2, in preprocess_product_mention\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\", line 882, in __getitem__\n    return self._get_value(key)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\", line 989, in _get_value\n    loc = self.index.get_loc(label)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2897, in get_loc\n    raise KeyError(key) from err\nKeyError: 'product_mention'\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "model_funcs = {\n",
    "    'Logistic Regression': lambda: LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': lambda: RandomForestClassifier(),\n",
    "    'XGBoost': build_xgboost_model,\n",
    "    'LSTM': build_lstm_model,\n",
    "    'Bidirectional LSTM': build_bidirectional_lstm_model,\n",
    "    'CNN + LSTM': build_cnn_lstm_model,\n",
    "    'Deep NN': build_deep_nn_model\n",
    "}\n",
    "\n",
    "# Create and tune models\n",
    "results = {}\n",
    "\n",
    "for name, model_func in model_funcs.items():\n",
    "    print(f\"\\nTuning model: {name}\")\n",
    "    if name in ['LSTM', 'Bidirectional LSTM', 'CNN + LSTM', 'Deep NN']:\n",
    "        pipeline = create_pipeline(model_func, epochs=10)\n",
    "    else:\n",
    "        pipeline = create_pipeline(model_func)\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grids[name], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1) if name not in ['XGBoost'] else y_pred\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "    accuracy = grid_search.best_score_\n",
    "    results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'accuracy': accuracy,\n",
    "        'y_pred': y_pred,\n",
    "        'classification_report': classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_),\n",
    "        'confusion_matrix': confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    }\n",
    "    print(f\"\\n{name} Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{name} Best Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print Classification Report\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(results[name]['classification_report'])\n",
    "\n",
    "    # Print Confusion Matrix\n",
    "    print(f\"\\n{name} Confusion Matrix:\")\n",
    "    cm = results[name]['confusion_matrix']\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'{name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Compare results\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "print(f\"\\nBest Model: {best_model_name} with Accuracy: {results[best_model_name]['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4",
   "language": "python",
   "name": "nombre_del_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
