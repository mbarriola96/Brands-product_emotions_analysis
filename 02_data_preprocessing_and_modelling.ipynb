{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to clean and preprocess tweets\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove strange characters and punctuation\n",
    "    strange_chars = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~“!#Ûª'\n",
    "    text = text.translate(str.maketrans(strange_chars, ' ' * len(strange_chars)))\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_product_mention(df):\n",
    "    df['product_mention'] = df['product_mention'].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Import the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_type</th>\n",
       "      <th>product_mention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text      emotion_type  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  Negative emotion   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  Positive emotion   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...  Positive emotion   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  Negative emotion   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  Positive emotion   \n",
       "\n",
       "  product_mention  \n",
       "0           Apple  \n",
       "1           Apple  \n",
       "2           Apple  \n",
       "3           Apple  \n",
       "4          Google  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "df = pd.read_csv('df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "df['cleaned_text'] = df['tweet_text'].apply(clean_text)\n",
    "\n",
    "# Prepare features and labels\n",
    "texts = df['cleaned_text']\n",
    "product_mentions = df['product_mention']\n",
    "labels = df['emotion_type']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "labels_categorical = to_categorical(labels_encoded)\n",
    "\n",
    "# Define preprocessing for text and product mention\n",
    "text_preprocessor = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, max_df=0.7, min_df=5))\n",
    "])\n",
    "\n",
    "product_mention_preprocessor = Pipeline([\n",
    "    ('preprocessor', FunctionTransformer(preprocess_product_mention, validate=False)),\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create Column Transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cleaned_text', text_preprocessor, 'cleaned_text'),\n",
    "        ('product_mention', product_mention_preprocessor, 'product_mention')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define models\n",
    "def build_lstm_model(epochs=10):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_bidirectional_lstm_model(epochs=10):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    model.add(Bidirectional(LSTM(128)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_cnn_lstm_model(epochs=10):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_deep_nn_model(epochs=10):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=100))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# XGBoost model\n",
    "def build_xgboost_model():\n",
    "    return XGBClassifier(eval_metric='mlogloss')\n",
    "\n",
    "# Create a pipeline with preprocessing and model\n",
    "def create_pipeline(model_func, **kwargs):\n",
    "    return Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', model_func(**kwargs))\n",
    "    ])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['cleaned_text', 'product_mention']], labels_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define parameter grids for tuning\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'classifier__C': [0.1, 1, 10]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__max_depth': [10, 20]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'classifier__n_estimators': [100, 200],\n",
    "        'classifier__learning_rate': [0.01, 0.1]\n",
    "    },\n",
    "    'LSTM': {'classifier__epochs': [5, 10, 15]},\n",
    "    'Bidirectional LSTM': {'classifier__epochs': [5, 10, 15]},\n",
    "    'CNN + LSTM': {'classifier__epochs': [5, 10, 15]},\n",
    "    'Deep NN': {'classifier__epochs': [5, 10, 15]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning model: Logistic Regression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 9 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2895, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 98, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index_class_helper.pxi\", line 93, in pandas._libs.index.Int64Engine._check_type\nKeyError: 'product_mention'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 754, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 681, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n    return super().__call__(iterable_with_config)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 240, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 312, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"<ipython-input-3-be33faf0ed4d>\", line 2, in preprocess_product_mention\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\", line 882, in __getitem__\n    return self._get_value(key)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\", line 989, in _get_value\n    loc = self.index.get_loc(label)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2897, in get_loc\n    raise KeyError(key) from err\nKeyError: 'product_mention'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2690d14011dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1150\u001b[0m                 )\n\u001b[0;32m   1151\u001b[0m             ):\n\u001b[1;32m-> 1152\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    896\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1421\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1422\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    873\u001b[0m                     )\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m                 \u001b[1;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             )\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 9 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n9 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2895, in get_loc\n    return self._engine.get_loc(casted_key)\n  File \"pandas\\_libs\\index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index.pyx\", line 98, in pandas._libs.index.IndexEngine.get_loc\n  File \"pandas\\_libs\\index_class_helper.pxi\", line 93, in pandas._libs.index.Int64Engine._check_type\nKeyError: 'product_mention'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 754, in fit_transform\n    result = self._fit_transform(X, y, _fit_transform_one)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 681, in _fit_transform\n    return Parallel(n_jobs=self.n_jobs)(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n    return super().__call__(iterable_with_config)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit_transform\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\", line 957, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\", line 919, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 157, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 240, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 312, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"<ipython-input-3-be33faf0ed4d>\", line 2, in preprocess_product_mention\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\", line 882, in __getitem__\n    return self._get_value(key)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\", line 989, in _get_value\n    loc = self.index.get_loc(label)\n  File \"C:\\Users\\Usuario\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 2897, in get_loc\n    raise KeyError(key) from err\nKeyError: 'product_mention'\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "model_funcs = {\n",
    "    'Logistic Regression': lambda: LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': lambda: RandomForestClassifier(),\n",
    "    'XGBoost': build_xgboost_model,\n",
    "    'LSTM': build_lstm_model,\n",
    "    'Bidirectional LSTM': build_bidirectional_lstm_model,\n",
    "    'CNN + LSTM': build_cnn_lstm_model,\n",
    "    'Deep NN': build_deep_nn_model\n",
    "}\n",
    "\n",
    "# Create and tune models\n",
    "results = {}\n",
    "\n",
    "for name, model_func in model_funcs.items():\n",
    "    print(f\"\\nTuning model: {name}\")\n",
    "    if name in ['LSTM', 'Bidirectional LSTM', 'CNN + LSTM', 'Deep NN']:\n",
    "        pipeline = create_pipeline(model_func, epochs=10)\n",
    "    else:\n",
    "        pipeline = create_pipeline(model_func)\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grids[name], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1) if name not in ['XGBoost'] else y_pred\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "    accuracy = grid_search.best_score_\n",
    "    results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'accuracy': accuracy,\n",
    "        'y_pred': y_pred,\n",
    "        'classification_report': classification_report(y_true_classes, y_pred_classes, target_names=label_encoder.classes_),\n",
    "        'confusion_matrix': confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    }\n",
    "    print(f\"\\n{name} Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{name} Best Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print Classification Report\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(results[name]['classification_report'])\n",
    "\n",
    "    # Print Confusion Matrix\n",
    "    print(f\"\\n{name} Confusion Matrix:\")\n",
    "    cm = results[name]['confusion_matrix']\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'{name} Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Compare results\n",
    "best_model_name = max(results, key=lambda x: results[x]['accuracy'])\n",
    "print(f\"\\nBest Model: {best_model_name} with Accuracy: {results[best_model_name]['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4",
   "language": "python",
   "name": "nombre_del_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
